{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifier_lewidi import *\n",
    "from params_lewidi import *\n",
    "from DataManager import *\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "filepath1 = '../data/ConvAbuse_dataset/'\n",
    "filepath2 = '../data/ArMIS_dataset/'\n",
    "filepath3 = '../data/HS-Brexit_dataset/'\n",
    "filepath4 = '../data/MD-Agreement_dataset/'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello5\n",
      "I'm in with the conv_train dataset\n",
      "I'm in with the conv_dev dataset\n",
      "I'm in with the ar_train dataset\n",
      "I'm in with the ar_dev dataset\n",
      "I'm in with the br_train dataset\n",
      "I'm in with the br_dev dataset\n",
      "I'm in with the md_train dataset\n",
      "I'm in with the md_dev dataset\n",
      "hello6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = DataManager(filepath1, filepath2, filepath3, filepath4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'conv_train':                                  text annotations      annotators  \\\n",
      "0                                 yes       1,1,1  Ann2,Ann3,Ann7   \n",
      "1         were you not ten years old?       1,1,1  Ann3,Ann7,Ann8   \n",
      "2                                 yea        -1,1       Ann1,Ann7   \n",
      "3                              Ibadan         1,1       Ann3,Ann6   \n",
      "4                           Bangalore       1,1,1  Ann1,Ann2,Ann3   \n",
      "...                               ...         ...             ...   \n",
      "2393  more worthless fucking bot spam    -2,-2,-2  Ann1,Ann4,Ann8   \n",
      "2394                          fuck no     -1,-1,0  Ann1,Ann6,Ann7   \n",
      "2395                             fuck    -1,-2,-1  Ann1,Ann2,Ann3   \n",
      "2396                      yes it does       1,1,1  Ann4,Ann6,Ann7   \n",
      "2397                      i dont know       1,1,1  Ann2,Ann3,Ann5   \n",
      "\n",
      "      soft_label_0  soft_label_1 hard_label  \n",
      "0            1.000         0.000          0  \n",
      "1            1.000         0.000          0  \n",
      "2            0.500         0.500          0  \n",
      "3            1.000         0.000          0  \n",
      "4            1.000         0.000          0  \n",
      "...            ...           ...        ...  \n",
      "2393         0.000         1.000          1  \n",
      "2394         0.333         0.667          1  \n",
      "2395         0.000         1.000          1  \n",
      "2396         1.000         0.000          0  \n",
      "2397         1.000         0.000          0  \n",
      "\n",
      "[2398 rows x 6 columns], 'conv_dev':                                                text  annotations  \\\n",
      "0                          What are carbon offsets?  1,1,1,1,1,1   \n",
      "1                                      thanksgiving  1,1,1,1,1,1   \n",
      "2                                               yes        1,1,1   \n",
      "3                                               Yes    1,1,1,1,1   \n",
      "4                                             bitch  -2,-2,-3,-2   \n",
      "..                                              ...          ...   \n",
      "807                            do your have money ?        1,1,0   \n",
      "808                                         Jakarta        1,1,1   \n",
      "809  orlando that's not where I will be flying from          1,1   \n",
      "810                                            was?          1,1   \n",
      "811                          my father is a bastard     -2,-1,-1   \n",
      "\n",
      "                        annotators  soft_label_0  soft_label_1  hard_label  \n",
      "0    Ann2,Ann3,Ann4,Ann5,Ann6,Ann8           NaN           NaN         NaN  \n",
      "1    Ann2,Ann3,Ann5,Ann6,Ann7,Ann8           NaN           NaN         NaN  \n",
      "2                   Ann1,Ann4,Ann7           NaN           NaN         NaN  \n",
      "3         Ann2,Ann5,Ann6,Ann7,Ann8           NaN           NaN         NaN  \n",
      "4              Ann3,Ann4,Ann5,Ann6           NaN           NaN         NaN  \n",
      "..                             ...           ...           ...         ...  \n",
      "807                 Ann2,Ann4,Ann5           NaN           NaN         NaN  \n",
      "808                 Ann1,Ann2,Ann3           NaN           NaN         NaN  \n",
      "809                      Ann2,Ann7           NaN           NaN         NaN  \n",
      "810                      Ann4,Ann7           NaN           NaN         NaN  \n",
      "811                 Ann5,Ann6,Ann7           NaN           NaN         NaN  \n",
      "\n",
      "[812 rows x 6 columns], 'ar_train':                                                   text annotations  \\\n",
      "0     ÙŠØ¹Ù†ÙŠ Ù†ØµÙŠØ± Ø±Ø¬Ù„ Ù‚ÙˆÙ„ØªÙƒ ÙˆØ¨Ø¹Ø¯ÙŠÙ† Ø§Ø°Ø§ Ø§Ù„ÙˆØ­Ø¯Ù‡ ØªØ¨Ø§ ØªØ³Ø±...       0,0,0   \n",
      "1    Ù†Ø³ÙˆÙŠØ§Øª Ø¹Ù…Ø§Ù† ÙˆØ§Ù„Ù…ØªØ³ØªØ± Ø¨ØªØ¶Ø®ÙŠÙ… Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø¹Ù†Ù ØµØ¯ÙØ© Ø³...       1,0,1   \n",
      "2    ØªØ´Ø§Ø± Ø§Ù„ÙÙƒØ± Ø§Ù„Ù†Ø³ÙˆÙŠ Ø§Ù„Ù‚Ø¯ ÙˆØ¯Ø¹ÙˆØ© Ø§Ù„Ù†Ø³ÙˆÙŠØ§Øª Ø§Ù„Ø§Ù†Ø­Ù„Ø§Ù„...       1,1,1   \n",
      "3                    Ø§Ù„Ù‰ Ø§Ù„Ù† Ø§Ù„Ù„ Ø§Ø­Ø§ Ø§Ù„Ù„ ØªØ£Ù…Ù„ÙŠ Ù‡Ø°Ø© Ø§Ù„Ø£       0,0,0   \n",
      "4                      Ø³Ø¹ÙˆØ¯ÙŠØ§Øª ØµØ§ÙŠØ¹Ø§Øª ÙŠØªÙ†Ù‚Ù„Ùˆ ÙˆØ§Ø­Ø¯ Ù„Ù„Ø«Ø§       0,0,1   \n",
      "..                                                 ...         ...   \n",
      "652  ØªØ±Ù… Ø¬Ø¯Ø§ ÙˆÙ…Ù†Ø·Ù‚ÙŠ ÙˆØ·Ø±Ø­Ø¬ Ù…Ø¹Ù‚ÙˆÙ„ Ø§ØºÙ„Ø¨ Ø§ÙƒØ¯Ø± Ø§ÙƒÙˆÙ„ Ø§Ù„Ù†Ø³...       1,1,0   \n",
      "653  Øª Ø§Ù„Ø¢Ù„Ø§Ù Ø§Ù„ÙØªÙŠØ§Øª ÙˆØ§Ù„Ù†Ø³Ø§Ø¡ ÙŠÙˆÙ…ÙŠØ§ Ø¬Ù…ÙŠØ¹ Ø£Ù†Ø­Ø§Ø¡ Ø§Ù„Ø¹Ø§...       0,0,0   \n",
      "654  Ø§Ù„Ø¯Ø§Ø®Ù„ ÙˆØ§Ù„Ø®Ø§Ø±Ø¬ Ø³Ø§ÙØ±Ø§Øª ÙˆÙ…ØªØ¹Ø¯ÙŠØ§Øª Ø­Ø¯ÙˆØ¯ Ø§Ù„Ø¯ÙŠÙ† ØªØ­Ø¯ÙŠ...       1,1,0   \n",
      "655  Ø§ØµØ¯ÙŠÙ‚ÙŠ Ø§Ù†Ø§ Ø§Ø´ÙÙ‚ Ø¹Ù„ÙŠÙ‡Ø§ ÙŠØ³Ø¹ÙÙ‡Ø§ Ø¹Ù‚Ù„Ù‡Ø§ ÙˆÙ„Ù… ÙŠØ³Ø¹ÙÙ‡Ø§ ...       1,1,1   \n",
      "656  Ù†Ù‡Ø§ Ù„Ø­Ø¯ÙŠØ« Ù…Ø¹Ù†Ø§Ù‡ Ø§Ù„Ù†Ø³Ø§Ø¡ Ù†Ø§Ù‚ØµØ§Øª Ø¹Ù‚Ù„ ÙˆØ¯ÙŠÙ† Ø§Ù„Ø¯ÙŠÙ† Ù†...       0,0,0   \n",
      "\n",
      "         annotators  soft_label_0  soft_label_1 hard_label  \n",
      "0    Ann1,Ann2,Ann3          1.00          0.00          0  \n",
      "1    Ann1,Ann2,Ann3          0.33          0.67          1  \n",
      "2    Ann1,Ann2,Ann3          0.00          1.00          1  \n",
      "3    Ann1,Ann2,Ann3          1.00          0.00          0  \n",
      "4    Ann1,Ann2,Ann3          0.67          0.33          0  \n",
      "..              ...           ...           ...        ...  \n",
      "652  Ann1,Ann2,Ann3          0.33          0.67          1  \n",
      "653  Ann1,Ann2,Ann3          1.00          0.00          0  \n",
      "654  Ann1,Ann2,Ann3          0.33          0.67          1  \n",
      "655  Ann1,Ann2,Ann3          0.00          1.00          1  \n",
      "656  Ann1,Ann2,Ann3          1.00          0.00          0  \n",
      "\n",
      "[657 rows x 6 columns], 'ar_dev':                                                   text annotations  \\\n",
      "0    Ø£ Ø§Ø³Ø¦Ù„Ø© Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª ÙŠØ³ØªØºØ±Ø¨ Ø§Ù†Ù‡Ù… ÙŠØ¹Ù…Ù„ÙˆÙ† Ù…Ø¹Ù†Ø§ Ù†ÙØ³ Ø§...       1,0,0   \n",
      "1                                           Ø§Øª  Ø§Ù„ÙØ³ÙˆÙŠ       1,1,1   \n",
      "2    Ù€ Ø¨Ø³ÙŠØ· Ø§ØªÙˆÙ‚Ø¹ ØªÙƒÙ„Ù…Ù†Ø§ Ø§Ù„ØªÙˆÙŠØªØ± Ø¯ÙˆØ±Ø§Øª ÙˆÙ…Ø­Ø§Ø¶Ø±Ø§Øª ÙˆÙ†Ø­...       1,0,1   \n",
      "3    ÙˆÙƒØ¯ Ø§Ø³ØªÙ†ØªØ§Ø¬ÙŠ Ø¨Ø¥Ù† Ø§Ù„Ù†Ø³ÙˆÙŠØ§Øª Ù‚Ø³Ù…ÙŠÙ† Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ø£ÙˆÙ„ Ø¹Ùˆ...       1,0,1   \n",
      "4                                   ÙŠ Ù‚Ù„ØªÙŠ Ø§Ù„Ù†Ø³ÙˆÙŠÙ‡ Ø§Ù…Ø±       0,0,0   \n",
      "..                                                 ...         ...   \n",
      "136            Øª Ø§Ù„Ù‚ØªØ§Ù„ÙŠØ© Ø­ÙŠÙ„Ø© Ù†Ø³Ø§Ø¡ Ù„Ù…ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø¹Ù†Ù Ø§Ù„Ù…Ø±       0,0,0   \n",
      "137           ÙˆØ¹ Ø§Ù„ÙØ³ÙˆÙŠØ§Øª Ù„Ø§Ù†Ù‡Ø§ ØªØ¬ÙŠØ¨ Ù„Ø­Ø§Ù„Ù‡Ø§ Ø§Ù„Ù…Ø³Ø¨Ù‡ ØªÙ†Ø³       1,0,1   \n",
      "138   Ø§Ø®ÙˆØ§ØªÙƒ ÙˆØ¨Ø¹Ø¯ÙŠÙ† ØªÙƒÙ„Ù… Ù…ÙƒØ§Ù† ØµØ§ÙŠØ¹Ø§Øª ... Ø¹Ù†Ø¯ÙƒÙ… Ø²ÙŠØ§Ø¯...       0,1,1   \n",
      "139  ÙŠØ´ ÙŠØ­Ø·ÙˆÙ† Ø´ÙŠØ¡ Ø¨Ø§Ù„Ù†Ø³ÙˆÙŠÙ‡ Ø®ÙŠØ± Ù…Ø§Ù„Ù‚ÙˆØ§ Ø³Ø¨Ø¨ Ù‚Ø§Ù„ÙˆØ§ Ù†Ø³Ùˆ...       0,0,0   \n",
      "140  Ù† ÙŠÙƒÙˆÙ† Ø¨Ø¹Ù† ÙÙ‡Ø§ Ù„ÙŠÙ‡ ØºØ¨ÙŠØ© Ù‡Ø§ÙŠ Ø£ÙÙƒØ§Ø±Ù‡Ø§ Ù…Ø«Ù„ Ù†Ø³Ø§Ø¡ Ø¨...       1,0,1   \n",
      "\n",
      "         annotators  soft_label_0  soft_label_1  hard_label  \n",
      "0    Ann1,Ann2,Ann3           NaN           NaN         NaN  \n",
      "1    Ann1,Ann2,Ann3           NaN           NaN         NaN  \n",
      "2    Ann1,Ann2,Ann3           NaN           NaN         NaN  \n",
      "3    Ann1,Ann2,Ann3           NaN           NaN         NaN  \n",
      "4    Ann1,Ann2,Ann3           NaN           NaN         NaN  \n",
      "..              ...           ...           ...         ...  \n",
      "136  Ann1,Ann2,Ann3           NaN           NaN         NaN  \n",
      "137  Ann1,Ann2,Ann3           NaN           NaN         NaN  \n",
      "138  Ann1,Ann2,Ann3           NaN           NaN         NaN  \n",
      "139  Ann1,Ann2,Ann3           NaN           NaN         NaN  \n",
      "140  Ann1,Ann2,Ann3           NaN           NaN         NaN  \n",
      "\n",
      "[141 rows x 6 columns], 'br_train':                                                   text  annotations  \\\n",
      "0    m so glad about #Brexit.. My ancestors are fro...  0,0,0,0,0,0   \n",
      "1       here was more to #Brexit than immigration uggh  0,0,0,0,0,0   \n",
      "2    end of the day, the leave campaign won #Brexit...  0,0,0,0,0,0   \n",
      "3    reducing migration thing wasn't quite what it ...  0,0,0,0,0,0   \n",
      "4                                                       0,0,0,0,0,0   \n",
      "..                                                 ...          ...   \n",
      "779   has to happen there is no way you can set a m...  0,0,0,0,0,0   \n",
      "780                                       o is he? <ur  0,0,0,0,0,0   \n",
      "781  ny is we will probably now look to appoint a f...  0,0,0,0,0,0   \n",
      "782  watch out Merkel, the German people don't like...  0,0,1,1,1,0   \n",
      "783   is served.  In 2015, $66.4B of intl capital f...  0,0,0,0,0,0   \n",
      "\n",
      "                        annotators  soft_label_0  soft_label_1 hard_label  \n",
      "0    Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           1.0           0.0          0  \n",
      "1    Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           1.0           0.0          0  \n",
      "2    Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           1.0           0.0          0  \n",
      "3    Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           1.0           0.0          0  \n",
      "4    Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           1.0           0.0          0  \n",
      "..                             ...           ...           ...        ...  \n",
      "779  Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           1.0           0.0          0  \n",
      "780  Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           1.0           0.0          0  \n",
      "781  Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           1.0           0.0          0  \n",
      "782  Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           0.5           0.5          0  \n",
      "783  Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           1.0           0.0          0  \n",
      "\n",
      "[784 rows x 6 columns], 'br_dev':                                                   text  annotations  \\\n",
      "0     means foreigners will be flocking here this s...  0,0,0,0,0,0   \n",
      "1    OrNot ?? Easy!! #BREXIT and protect your count...  0,0,0,1,1,0   \n",
      "2    rexit to sum it up in just one word \"terrorism...  0,0,0,1,1,1   \n",
      "3    ays #Brexit reflects unhappiness with migratio...  0,0,0,0,0,0   \n",
      "4     is looking likely. but anti-immigration is mu...  0,0,0,0,0,0   \n",
      "..                                                 ...          ...   \n",
      "163  s is interviewing a guy from \"Muslims for Brit...  0,0,0,0,0,0   \n",
      "164  his #brexit, is there anyway we can deport Mar...  0,1,0,1,0,1   \n",
      "165  rope is collapsing, don't worry we welcome ref...  0,0,0,1,1,0   \n",
      "166   its now cheaper for foreign tourists to come ...  0,0,0,0,0,0   \n",
      "167  xit is a reclaiming of England's independence!...  0,0,0,0,0,0   \n",
      "\n",
      "                        annotators  soft_label_0  soft_label_1  hard_label  \n",
      "0    Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           NaN           NaN         NaN  \n",
      "1    Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           NaN           NaN         NaN  \n",
      "2    Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           NaN           NaN         NaN  \n",
      "3    Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           NaN           NaN         NaN  \n",
      "4    Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           NaN           NaN         NaN  \n",
      "..                             ...           ...           ...         ...  \n",
      "163  Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           NaN           NaN         NaN  \n",
      "164  Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           NaN           NaN         NaN  \n",
      "165  Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           NaN           NaN         NaN  \n",
      "166  Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           NaN           NaN         NaN  \n",
      "167  Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           NaN           NaN         NaN  \n",
      "\n",
      "[168 rows x 6 columns], 'md_train':                                                    text annotations  \\\n",
      "0                                              way Jose   0,0,0,0,0   \n",
      "1                     d, what is the matter with people   0,0,0,0,0   \n",
      "2      the Kurds are helping the ppl Of the Ukraine ...   0,0,0,0,1   \n",
      "3                                WRONG with these peopl   0,0,0,0,0   \n",
      "4     is earpiece too plus a wire on his sleeves! #C...   1,0,0,0,0   \n",
      "...                                                 ...         ...   \n",
      "6587   of showing compassion and empathy..this Presi...   0,0,0,0,0   \n",
      "6588                                        ither did y   0,0,0,0,0   \n",
      "6589  sity of Toronto, McMaster University, Sunnybro...   0,0,0,0,0   \n",
      "6590  y people ripping this country apart are your f...   0,1,1,0,0   \n",
      "6591  !  #Repost miss_pr_piggy ãƒ»ãƒ»ãƒ» \"Gen Z will sure ...   0,0,0,0,0   \n",
      "\n",
      "                              annotators  soft_label_0  soft_label_1  \\\n",
      "0     Ann418,Ann266,Ann149,Ann730,Ann345           1.0           0.0   \n",
      "1     Ann733,Ann422,Ann779,Ann514,Ann777           1.0           0.0   \n",
      "2     Ann425,Ann511,Ann779,Ann420,Ann721           0.8           0.2   \n",
      "3     Ann632,Ann179,Ann701,Ann201,Ann661           1.0           0.0   \n",
      "4     Ann266,Ann168,Ann149,Ann381,Ann774           0.8           0.2   \n",
      "...                                  ...           ...           ...   \n",
      "6587   Ann740,Ann577,Ann65,Ann775,Ann681           1.0           0.0   \n",
      "6588    Ann88,Ann85,Ann779,Ann793,Ann656           1.0           0.0   \n",
      "6589   Ann632,Ann517,Ann514,Ann64,Ann609           1.0           0.0   \n",
      "6590  Ann493,Ann586,Ann239,Ann347,Ann661           0.6           0.4   \n",
      "6591  Ann117,Ann513,Ann755,Ann455,Ann146           1.0           0.0   \n",
      "\n",
      "     hard_label  \n",
      "0             0  \n",
      "1             0  \n",
      "2             0  \n",
      "3             0  \n",
      "4             0  \n",
      "...         ...  \n",
      "6587          0  \n",
      "6588          0  \n",
      "6589          0  \n",
      "6590          0  \n",
      "6591          0  \n",
      "\n",
      "[6592 rows x 6 columns], 'md_dev':                                                    text annotations  \\\n",
      "0     POSE WHAT IS HIDDEN IN AREA 51? #Anonymous #an...   0,0,0,0,1   \n",
      "1     Departments need to be purged. Cop culture mus...   0,0,0,0,0   \n",
      "2     looked this way and that way, and when he saw ...   0,0,0,0,0   \n",
      "3     r the biggest piece of ğŸ’© on TV. How the hell c...   1,1,1,1,1   \n",
      "4     Remote Control is for things like this, soyo c...   0,1,0,1,0   \n",
      "...                                                 ...         ...   \n",
      "1099  et the scumbags on Wall Street try any funny b...   0,1,0,0,0   \n",
      "1100                       u are full of BS. #munchinLi   0,1,1,0,1   \n",
      "1101  x, too. Pat, how come you didn't have any oral...   1,1,1,1,1   \n",
      "1102  â€™s the only President in history to declare th...   0,1,0,1,0   \n",
      "1103             n what clowns you all are such tool ba   1,1,1,1,1   \n",
      "\n",
      "                              annotators  soft_label_0  soft_label_1  \\\n",
      "0     Ann423,Ann163,Ann553,Ann428,Ann757           NaN           NaN   \n",
      "1      Ann13,Ann117,Ann586,Ann241,Ann270           NaN           NaN   \n",
      "2     Ann138,Ann306,Ann149,Ann447,Ann274           NaN           NaN   \n",
      "3     Ann422,Ann546,Ann466,Ann681,Ann169           NaN           NaN   \n",
      "4     Ann188,Ann266,Ann232,Ann779,Ann718           NaN           NaN   \n",
      "...                                  ...           ...           ...   \n",
      "1099   Ann514,Ann57,Ann273,Ann589,Ann710           NaN           NaN   \n",
      "1100  Ann514,Ann379,Ann273,Ann748,Ann726           NaN           NaN   \n",
      "1101  Ann200,Ann811,Ann669,Ann369,Ann768           NaN           NaN   \n",
      "1102   Ann811,Ann64,Ann285,Ann173,Ann415           NaN           NaN   \n",
      "1103  Ann260,Ann140,Ann205,Ann779,Ann591           NaN           NaN   \n",
      "\n",
      "      hard_label  \n",
      "0            NaN  \n",
      "1            NaN  \n",
      "2            NaN  \n",
      "3            NaN  \n",
      "4            NaN  \n",
      "...          ...  \n",
      "1099         NaN  \n",
      "1100         NaN  \n",
      "1101         NaN  \n",
      "1102         NaN  \n",
      "1103         NaN  \n",
      "\n",
      "[1104 rows x 6 columns]})\n"
     ]
    }
   ],
   "source": [
    "print(data.dataset_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_params = params_lewidi()\n",
    "\n",
    "def_params.task = \"multi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431\n",
      "Data shape after majority voting (2398, 16)\n",
      "[('batch_size', 4), ('learning_rate', 1e-07), ('max_len', 128), ('num_epochs', 3), ('random_state', 9999), ('num_folds', 5), ('task', 'multi'), ('batch_weight', None), ('sort_by', None), ('stratified', True), ('predict', 'label'), ('mc_passes', 10)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "key = \"conv_train\"\n",
    "\n",
    "annotators = list(sorted(set(itertools.chain.from_iterable(data.dataset_groups[key]['annotators'].str.findall(\"\\w+\")))))\n",
    "    \n",
    "model = ToxicityClassifier(data.dataset_groups[key], annotators=annotators, params=def_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold # 1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m score, results \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mCV()\n\u001b[1;32m      3\u001b[0m score[\u001b[39m\"\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(key \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(val) \u001b[39mfor\u001b[39;00m key, val \u001b[39min\u001b[39;00m def_params\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m\u001b[39m.\u001b[39mitems())\n\u001b[1;32m      4\u001b[0m score[\u001b[39m\"\u001b[39m\u001b[39mtask\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mparams\u001b[39m.\u001b[39mtask\n",
      "File \u001b[0;32m~/scratch/lewidi_2023/code/classifier_lewidi.py:123\u001b[0m, in \u001b[0;36mToxicityClassifier.CV\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m scores, ensemble_results\n\u001b[1;32m    122\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_CV(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata)\n",
      "File \u001b[0;32m~/scratch/lewidi_2023/code/classifier_lewidi.py:152\u001b[0m, in \u001b[0;36mToxicityClassifier._CV\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    144\u001b[0m test \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mloc[test_idx]\u001b[39m.\u001b[39mreset_index()\n\u001b[1;32m    145\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[39mif i == 1:\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[39m  test.to_csv(os.path.join(self.params.source_dir, \"results\", \"GHC\", \"test_file.csv\"), index=False)\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[39melse:\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39m  test.to_csv(os.path.join(self.params.source_dir, \"results\", \"GHC\", \"test_file.csv\"), index=False, header=False, mode=\"a\")\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 152\u001b[0m train_batches \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_batches(train)\n\u001b[1;32m    153\u001b[0m test_batches \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_batches(test)\n\u001b[1;32m    155\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_model(train_batches)\n",
      "File \u001b[0;32m~/scratch/lewidi_2023/code/classifier_lewidi.py:403\u001b[0m, in \u001b[0;36mToxicityClassifier.get_batches\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    400\u001b[0m     anno_batch[task_label] \u001b[39m=\u001b[39m data[task_label]\u001b[39m.\u001b[39mtolist()[s: e]\n\u001b[1;32m    401\u001b[0m     mask_batch[task_label] \u001b[39m=\u001b[39m [i \u001b[39mfor\u001b[39;00m i, h \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(anno_batch[task_label]) \\\n\u001b[1;32m    402\u001b[0m                               \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m math\u001b[39m.\u001b[39misnan(h)]\n\u001b[0;32m--> 403\u001b[0m data_info[\u001b[39m\"\u001b[39;49m\u001b[39mlabels\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m=\u001b[39m anno_batch\n\u001b[1;32m    404\u001b[0m data_info[\u001b[39m\"\u001b[39m\u001b[39mmasks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m mask_batch\n\u001b[1;32m    406\u001b[0m \u001b[39m# data_info[\"majority_vote\"] = data[\"toxic\"].tolist()[s: e]\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "score, results = model.CV()\n",
    "\n",
    "score[\"params\"] = \", \".join(key + \": \" + str(val) for key, val in def_params.__dict__.items())\n",
    "score[\"task\"] = model.params.task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pacific = pytz.timezone('US/Pacific')\n",
    "sa_time = datetime.now(pacific)\n",
    "name_time = sa_time.strftime('%m%d%y-%H:%M')\n",
    "score[\"time\"] = name_time\n",
    "print(score)\n",
    "\n",
    "score_dir = os.path.join(def_params.source_dir, \"results\", \"GHC\", \"classification.csv\")\n",
    "result_dir = os.path.join(def_params.source_dir, \"results\", \"GHC\", name_time + \"_\" + def_params.task + \".csv\")\n",
    "if os.path.exists(score_dir):\n",
    "    pd.DataFrame.from_records([score]).to_csv(score_dir, header=False,  index=False, mode=\"a\")\n",
    "else:\n",
    "    pd.DataFrame.from_records([score]).to_csv(score_dir, index=False)\n",
    "\n",
    "    pd.DataFrame.from_dict(results).to_csv(result_dir, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('lewidi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ee0efadd74fe6f6eadb79affcde3681dbe393c6369e8c561aa7df3b7abce0814"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
