{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from classifier_lewidi import *\n",
    "# from params_lewidi import *\n",
    "from DataManager import *\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "filepath1 = '../data/ConvAbuse_dataset/'\n",
    "filepath2 = '../data/ArMIS_dataset/'\n",
    "filepath3 = '../data/HS-Brexit_dataset/'\n",
    "filepath4 = '../data/MD-Agreement_dataset/'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello3\n",
      "I'm in with the conv_train dataset\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[39m=\u001b[39m DataManager(filepath1, filepath2, filepath3, filepath4)\n",
      "File \u001b[0;32m~/scratch/lewidi_2023/code/DataManager.py:50\u001b[0m, in \u001b[0;36mDataManager.__init__\u001b[0;34m(self, filepathConv, filepathArMis, filepathBrex, filepathMD)\u001b[0m\n\u001b[1;32m     46\u001b[0m         flag \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m (flag \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m     49\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_groups[key] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_groups[key]\u001b[39m.\u001b[39mjoin(pd\u001b[39m.\u001b[39mDataFrame(\n\u001b[0;32m---> 50\u001b[0m                         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mannotation_annotator_split(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset_groups[key], flag), \n\u001b[1;32m     51\u001b[0m                         index\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_groups[key]\u001b[39m.\u001b[39mindex\n\u001b[1;32m     52\u001b[0m                         ))\n\u001b[1;32m     53\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mhello4\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/scratch/lewidi_2023/code/DataManager.py:139\u001b[0m, in \u001b[0;36mDataManager.annotation_annotator_split\u001b[0;34m(self, panda, flag)\u001b[0m\n\u001b[1;32m    137\u001b[0m Ann_index\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m;\n\u001b[1;32m    138\u001b[0m \u001b[39mfor\u001b[39;00m person \u001b[39min\u001b[39;00m annotators:\n\u001b[0;32m--> 139\u001b[0m     \u001b[39mif\u001b[39;00m person \u001b[39min\u001b[39;00m panda[\u001b[39m\"\u001b[39;49m\u001b[39mannotators\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mstr\u001b[39m.\u001b[39;49mfindall(\u001b[39m\"\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mw+\u001b[39;49m\u001b[39m\"\u001b[39;49m)[ind]:\n\u001b[1;32m    140\u001b[0m         Ann_dict[person]\u001b[39m.\u001b[39mappend(annotations[Ann_index]) \n\u001b[1;32m    141\u001b[0m         Ann_index\u001b[39m=\u001b[39m\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/lewidi/lib/python3.10/site-packages/pandas/core/strings/accessor.py:129\u001b[0m, in \u001b[0;36mforbid_nonstring_types.<locals>._forbid_nonstring_types.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    125\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot use .str.\u001b[39m\u001b[39m{\u001b[39;00mfunc_name\u001b[39m}\u001b[39;00m\u001b[39m with values of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minferred dtype \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_dtype\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    127\u001b[0m     )\n\u001b[1;32m    128\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 129\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/lewidi/lib/python3.10/site-packages/pandas/core/strings/accessor.py:2515\u001b[0m, in \u001b[0;36mStringMethods.findall\u001b[0;34m(self, pat, flags)\u001b[0m\n\u001b[1;32m   2425\u001b[0m \u001b[39m@forbid_nonstring_types\u001b[39m([\u001b[39m\"\u001b[39m\u001b[39mbytes\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m   2426\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfindall\u001b[39m(\u001b[39mself\u001b[39m, pat, flags\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m   2427\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2428\u001b[0m \u001b[39m    Find all occurrences of pattern or regular expression in the Series/Index.\u001b[39;00m\n\u001b[1;32m   2429\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2513\u001b[0m \u001b[39m    dtype: object\u001b[39;00m\n\u001b[1;32m   2514\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2515\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data\u001b[39m.\u001b[39;49marray\u001b[39m.\u001b[39;49m_str_findall(pat, flags)\n\u001b[1;32m   2516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_result(result, returns_string\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/lewidi/lib/python3.10/site-packages/pandas/core/strings/object_array.py:247\u001b[0m, in \u001b[0;36mObjectStringArrayMixin._str_findall\u001b[0;34m(self, pat, flags)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_str_findall\u001b[39m(\u001b[39mself\u001b[39m, pat, flags\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m    246\u001b[0m     regex \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39mcompile(pat, flags\u001b[39m=\u001b[39mflags)\n\u001b[0;32m--> 247\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_str_map(regex\u001b[39m.\u001b[39;49mfindall, dtype\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mobject\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/lewidi/lib/python3.10/site-packages/pandas/core/strings/object_array.py:71\u001b[0m, in \u001b[0;36mObjectStringArrayMixin._str_map\u001b[0;34m(self, f, na_value, dtype, convert)\u001b[0m\n\u001b[1;32m     69\u001b[0m map_convert \u001b[39m=\u001b[39m convert \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39mall(mask)\n\u001b[1;32m     70\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 71\u001b[0m     result \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer_mask(arr, f, mask\u001b[39m.\u001b[39;49mview(np\u001b[39m.\u001b[39;49muint8), map_convert)\n\u001b[1;32m     72\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mAttributeError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m     73\u001b[0m     \u001b[39m# Reraise the exception if callable `f` got wrong number of args.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m     \u001b[39m# The user may want to be warned by this, instead of getting NaN\u001b[39;00m\n\u001b[1;32m     75\u001b[0m     p_err \u001b[39m=\u001b[39m (\n\u001b[1;32m     76\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m((takes)|(missing)) (?(2)from \u001b[39m\u001b[39m\\\u001b[39m\u001b[39md+ to )?\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md+ \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     77\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(?(3)required )positional arguments?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     78\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/lewidi/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2879\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer_mask\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/lewidi/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2509\u001b[0m, in \u001b[0;36mpandas._libs.lib.maybe_convert_objects\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/lewidi/lib/python3.10/site-packages/numpy/core/numeric.py:289\u001b[0m, in \u001b[0;36mfull\u001b[0;34m(shape, fill_value, dtype, order, like)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_full_dispatcher\u001b[39m(shape, fill_value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, order\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m, like\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    286\u001b[0m     \u001b[39mreturn\u001b[39;00m(like,)\n\u001b[0;32m--> 289\u001b[0m \u001b[39m@set_array_function_like_doc\u001b[39m\n\u001b[1;32m    290\u001b[0m \u001b[39m@set_module\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    291\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfull\u001b[39m(shape, fill_value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, order\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m*\u001b[39m, like\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    292\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[39m    Return a new array of given shape and type, filled with `fill_value`.\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    337\u001b[0m     \u001b[39mif\u001b[39;00m like \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "data = DataManager(filepath1, filepath2, filepath3, filepath4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'conv_train':                                  text annotations      annotators  \\\n",
      "0                                 yes       1,1,1  Ann2,Ann3,Ann7   \n",
      "1         were you not ten years old?       1,1,1  Ann3,Ann7,Ann8   \n",
      "2                                 yea        -1,1       Ann1,Ann7   \n",
      "3                              Ibadan         1,1       Ann3,Ann6   \n",
      "4                           Bangalore       1,1,1  Ann1,Ann2,Ann3   \n",
      "...                               ...         ...             ...   \n",
      "2393  more worthless fucking bot spam    -2,-2,-2  Ann1,Ann4,Ann8   \n",
      "2394                          fuck no     -1,-1,0  Ann1,Ann6,Ann7   \n",
      "2395                             fuck    -1,-2,-1  Ann1,Ann2,Ann3   \n",
      "2396                      yes it does       1,1,1  Ann4,Ann6,Ann7   \n",
      "2397                      i dont know       1,1,1  Ann2,Ann3,Ann5   \n",
      "\n",
      "      soft_label_0  soft_label_1 hard_label  \n",
      "0            1.000         0.000          0  \n",
      "1            1.000         0.000          0  \n",
      "2            0.500         0.500          0  \n",
      "3            1.000         0.000          0  \n",
      "4            1.000         0.000          0  \n",
      "...            ...           ...        ...  \n",
      "2393         0.000         1.000          1  \n",
      "2394         0.333         0.667          1  \n",
      "2395         0.000         1.000          1  \n",
      "2396         1.000         0.000          0  \n",
      "2397         1.000         0.000          0  \n",
      "\n",
      "[2398 rows x 6 columns], 'conv_dev':                                                text  annotations  \\\n",
      "0                          What are carbon offsets?  1,1,1,1,1,1   \n",
      "1                                      thanksgiving  1,1,1,1,1,1   \n",
      "2                                               yes        1,1,1   \n",
      "3                                               Yes    1,1,1,1,1   \n",
      "4                                             bitch  -2,-2,-3,-2   \n",
      "..                                              ...          ...   \n",
      "807                            do your have money ?        1,1,0   \n",
      "808                                         Jakarta        1,1,1   \n",
      "809  orlando that's not where I will be flying from          1,1   \n",
      "810                                            was?          1,1   \n",
      "811                          my father is a bastard     -2,-1,-1   \n",
      "\n",
      "                        annotators  soft_label_0  soft_label_1  hard_label  \n",
      "0    Ann2,Ann3,Ann4,Ann5,Ann6,Ann8           NaN           NaN         NaN  \n",
      "1    Ann2,Ann3,Ann5,Ann6,Ann7,Ann8           NaN           NaN         NaN  \n",
      "2                   Ann1,Ann4,Ann7           NaN           NaN         NaN  \n",
      "3         Ann2,Ann5,Ann6,Ann7,Ann8           NaN           NaN         NaN  \n",
      "4              Ann3,Ann4,Ann5,Ann6           NaN           NaN         NaN  \n",
      "..                             ...           ...           ...         ...  \n",
      "807                 Ann2,Ann4,Ann5           NaN           NaN         NaN  \n",
      "808                 Ann1,Ann2,Ann3           NaN           NaN         NaN  \n",
      "809                      Ann2,Ann7           NaN           NaN         NaN  \n",
      "810                      Ann4,Ann7           NaN           NaN         NaN  \n",
      "811                 Ann5,Ann6,Ann7           NaN           NaN         NaN  \n",
      "\n",
      "[812 rows x 6 columns], 'ar_train':                                                   text annotations  \\\n",
      "0     يعني نصير رجل قولتك وبعدين اذا الوحده تبا تسر...       0,0,0   \n",
      "1    نسويات عمان والمتستر بتضخيم حالات العنف صدفة س...       1,0,1   \n",
      "2    تشار الفكر النسوي القد ودعوة النسويات الانحلال...       1,1,1   \n",
      "3                    الى الن الل احا الل تأملي هذة الأ       0,0,0   \n",
      "4                      سعوديات صايعات يتنقلو واحد للثا       0,0,1   \n",
      "..                                                 ...         ...   \n",
      "652  ترم جدا ومنطقي وطرحج معقول اغلب اكدر اكول النس...       1,1,0   \n",
      "653  ت الآلاف الفتيات والنساء يوميا جميع أنحاء العا...       0,0,0   \n",
      "654  الداخل والخارج سافرات ومتعديات حدود الدين تحدي...       1,1,0   \n",
      "655  اصديقي انا اشفق عليها يسعفها عقلها ولم يسعفها ...       1,1,1   \n",
      "656  نها لحديث معناه النساء ناقصات عقل ودين الدين ن...       0,0,0   \n",
      "\n",
      "         annotators  soft_label_0  soft_label_1 hard_label  \n",
      "0    Ann1,Ann2,Ann3          1.00          0.00          0  \n",
      "1    Ann1,Ann2,Ann3          0.33          0.67          1  \n",
      "2    Ann1,Ann2,Ann3          0.00          1.00          1  \n",
      "3    Ann1,Ann2,Ann3          1.00          0.00          0  \n",
      "4    Ann1,Ann2,Ann3          0.67          0.33          0  \n",
      "..              ...           ...           ...        ...  \n",
      "652  Ann1,Ann2,Ann3          0.33          0.67          1  \n",
      "653  Ann1,Ann2,Ann3          1.00          0.00          0  \n",
      "654  Ann1,Ann2,Ann3          0.33          0.67          1  \n",
      "655  Ann1,Ann2,Ann3          0.00          1.00          1  \n",
      "656  Ann1,Ann2,Ann3          1.00          0.00          0  \n",
      "\n",
      "[657 rows x 6 columns], 'ar_dev':                                                   text annotations  \\\n",
      "0    أ اسئلة المعلمات يستغرب انهم يعملون معنا نفس ا...       1,0,0   \n",
      "1                                           ات  الفسوي       1,1,1   \n",
      "2    ـ بسيط اتوقع تكلمنا التويتر دورات ومحاضرات ونح...       1,0,1   \n",
      "3    وكد استنتاجي بإن النسويات قسمين القسم الأول عو...       1,0,1   \n",
      "4                                   ي قلتي النسويه امر       0,0,0   \n",
      "..                                                 ...         ...   \n",
      "136            ت القتالية حيلة نساء لمواجهة العنف المر       0,0,0   \n",
      "137           وع الفسويات لانها تجيب لحالها المسبه تنس       1,0,1   \n",
      "138   اخواتك وبعدين تكلم مكان صايعات ... عندكم زياد...       0,1,1   \n",
      "139  يش يحطون شيء بالنسويه خير مالقوا سبب قالوا نسو...       0,0,0   \n",
      "140  ن يكون بعن فها ليه غبية هاي أفكارها مثل نساء ب...       1,0,1   \n",
      "\n",
      "         annotators  soft_label_0  soft_label_1  hard_label  \n",
      "0    Ann1,Ann2,Ann3           NaN           NaN         NaN  \n",
      "1    Ann1,Ann2,Ann3           NaN           NaN         NaN  \n",
      "2    Ann1,Ann2,Ann3           NaN           NaN         NaN  \n",
      "3    Ann1,Ann2,Ann3           NaN           NaN         NaN  \n",
      "4    Ann1,Ann2,Ann3           NaN           NaN         NaN  \n",
      "..              ...           ...           ...         ...  \n",
      "136  Ann1,Ann2,Ann3           NaN           NaN         NaN  \n",
      "137  Ann1,Ann2,Ann3           NaN           NaN         NaN  \n",
      "138  Ann1,Ann2,Ann3           NaN           NaN         NaN  \n",
      "139  Ann1,Ann2,Ann3           NaN           NaN         NaN  \n",
      "140  Ann1,Ann2,Ann3           NaN           NaN         NaN  \n",
      "\n",
      "[141 rows x 6 columns], 'br_train':                                                   text  annotations  \\\n",
      "0    m so glad about #Brexit.. My ancestors are fro...  0,0,0,0,0,0   \n",
      "1       here was more to #Brexit than immigration uggh  0,0,0,0,0,0   \n",
      "2    end of the day, the leave campaign won #Brexit...  0,0,0,0,0,0   \n",
      "3    reducing migration thing wasn't quite what it ...  0,0,0,0,0,0   \n",
      "4                                                       0,0,0,0,0,0   \n",
      "..                                                 ...          ...   \n",
      "779   has to happen there is no way you can set a m...  0,0,0,0,0,0   \n",
      "780                                       o is he? <ur  0,0,0,0,0,0   \n",
      "781  ny is we will probably now look to appoint a f...  0,0,0,0,0,0   \n",
      "782  watch out Merkel, the German people don't like...  0,0,1,1,1,0   \n",
      "783   is served.  In 2015, $66.4B of intl capital f...  0,0,0,0,0,0   \n",
      "\n",
      "                        annotators  soft_label_0  soft_label_1 hard_label  \n",
      "0    Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           1.0           0.0          0  \n",
      "1    Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           1.0           0.0          0  \n",
      "2    Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           1.0           0.0          0  \n",
      "3    Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           1.0           0.0          0  \n",
      "4    Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           1.0           0.0          0  \n",
      "..                             ...           ...           ...        ...  \n",
      "779  Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           1.0           0.0          0  \n",
      "780  Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           1.0           0.0          0  \n",
      "781  Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           1.0           0.0          0  \n",
      "782  Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           0.5           0.5          0  \n",
      "783  Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           1.0           0.0          0  \n",
      "\n",
      "[784 rows x 6 columns], 'br_dev':                                                   text  annotations  \\\n",
      "0     means foreigners will be flocking here this s...  0,0,0,0,0,0   \n",
      "1    OrNot ?? Easy!! #BREXIT and protect your count...  0,0,0,1,1,0   \n",
      "2    rexit to sum it up in just one word \"terrorism...  0,0,0,1,1,1   \n",
      "3    ays #Brexit reflects unhappiness with migratio...  0,0,0,0,0,0   \n",
      "4     is looking likely. but anti-immigration is mu...  0,0,0,0,0,0   \n",
      "..                                                 ...          ...   \n",
      "163  s is interviewing a guy from \"Muslims for Brit...  0,0,0,0,0,0   \n",
      "164  his #brexit, is there anyway we can deport Mar...  0,1,0,1,0,1   \n",
      "165  rope is collapsing, don't worry we welcome ref...  0,0,0,1,1,0   \n",
      "166   its now cheaper for foreign tourists to come ...  0,0,0,0,0,0   \n",
      "167  xit is a reclaiming of England's independence!...  0,0,0,0,0,0   \n",
      "\n",
      "                        annotators  soft_label_0  soft_label_1  hard_label  \n",
      "0    Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           NaN           NaN         NaN  \n",
      "1    Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           NaN           NaN         NaN  \n",
      "2    Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           NaN           NaN         NaN  \n",
      "3    Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           NaN           NaN         NaN  \n",
      "4    Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           NaN           NaN         NaN  \n",
      "..                             ...           ...           ...         ...  \n",
      "163  Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           NaN           NaN         NaN  \n",
      "164  Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           NaN           NaN         NaN  \n",
      "165  Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           NaN           NaN         NaN  \n",
      "166  Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           NaN           NaN         NaN  \n",
      "167  Ann1,Ann2,Ann3,Ann4,Ann5,Ann6           NaN           NaN         NaN  \n",
      "\n",
      "[168 rows x 6 columns], 'md_train':                                                    text annotations  \\\n",
      "0                                              way Jose   0,0,0,0,0   \n",
      "1                     d, what is the matter with people   0,0,0,0,0   \n",
      "2      the Kurds are helping the ppl Of the Ukraine ...   0,0,0,0,1   \n",
      "3                                WRONG with these peopl   0,0,0,0,0   \n",
      "4     is earpiece too plus a wire on his sleeves! #C...   1,0,0,0,0   \n",
      "...                                                 ...         ...   \n",
      "6587   of showing compassion and empathy..this Presi...   0,0,0,0,0   \n",
      "6588                                        ither did y   0,0,0,0,0   \n",
      "6589  sity of Toronto, McMaster University, Sunnybro...   0,0,0,0,0   \n",
      "6590  y people ripping this country apart are your f...   0,1,1,0,0   \n",
      "6591  !  #Repost miss_pr_piggy ・・・ \"Gen Z will sure ...   0,0,0,0,0   \n",
      "\n",
      "                              annotators  soft_label_0  soft_label_1  \\\n",
      "0     Ann418,Ann266,Ann149,Ann730,Ann345           1.0           0.0   \n",
      "1     Ann733,Ann422,Ann779,Ann514,Ann777           1.0           0.0   \n",
      "2     Ann425,Ann511,Ann779,Ann420,Ann721           0.8           0.2   \n",
      "3     Ann632,Ann179,Ann701,Ann201,Ann661           1.0           0.0   \n",
      "4     Ann266,Ann168,Ann149,Ann381,Ann774           0.8           0.2   \n",
      "...                                  ...           ...           ...   \n",
      "6587   Ann740,Ann577,Ann65,Ann775,Ann681           1.0           0.0   \n",
      "6588    Ann88,Ann85,Ann779,Ann793,Ann656           1.0           0.0   \n",
      "6589   Ann632,Ann517,Ann514,Ann64,Ann609           1.0           0.0   \n",
      "6590  Ann493,Ann586,Ann239,Ann347,Ann661           0.6           0.4   \n",
      "6591  Ann117,Ann513,Ann755,Ann455,Ann146           1.0           0.0   \n",
      "\n",
      "     hard_label  \n",
      "0             0  \n",
      "1             0  \n",
      "2             0  \n",
      "3             0  \n",
      "4             0  \n",
      "...         ...  \n",
      "6587          0  \n",
      "6588          0  \n",
      "6589          0  \n",
      "6590          0  \n",
      "6591          0  \n",
      "\n",
      "[6592 rows x 6 columns], 'md_dev':                                                    text annotations  \\\n",
      "0     POSE WHAT IS HIDDEN IN AREA 51? #Anonymous #an...   0,0,0,0,1   \n",
      "1     Departments need to be purged. Cop culture mus...   0,0,0,0,0   \n",
      "2     looked this way and that way, and when he saw ...   0,0,0,0,0   \n",
      "3     r the biggest piece of 💩 on TV. How the hell c...   1,1,1,1,1   \n",
      "4     Remote Control is for things like this, soyo c...   0,1,0,1,0   \n",
      "...                                                 ...         ...   \n",
      "1099  et the scumbags on Wall Street try any funny b...   0,1,0,0,0   \n",
      "1100                       u are full of BS. #munchinLi   0,1,1,0,1   \n",
      "1101  x, too. Pat, how come you didn't have any oral...   1,1,1,1,1   \n",
      "1102  ’s the only President in history to declare th...   0,1,0,1,0   \n",
      "1103             n what clowns you all are such tool ba   1,1,1,1,1   \n",
      "\n",
      "                              annotators  soft_label_0  soft_label_1  \\\n",
      "0     Ann423,Ann163,Ann553,Ann428,Ann757           NaN           NaN   \n",
      "1      Ann13,Ann117,Ann586,Ann241,Ann270           NaN           NaN   \n",
      "2     Ann138,Ann306,Ann149,Ann447,Ann274           NaN           NaN   \n",
      "3     Ann422,Ann546,Ann466,Ann681,Ann169           NaN           NaN   \n",
      "4     Ann188,Ann266,Ann232,Ann779,Ann718           NaN           NaN   \n",
      "...                                  ...           ...           ...   \n",
      "1099   Ann514,Ann57,Ann273,Ann589,Ann710           NaN           NaN   \n",
      "1100  Ann514,Ann379,Ann273,Ann748,Ann726           NaN           NaN   \n",
      "1101  Ann200,Ann811,Ann669,Ann369,Ann768           NaN           NaN   \n",
      "1102   Ann811,Ann64,Ann285,Ann173,Ann415           NaN           NaN   \n",
      "1103  Ann260,Ann140,Ann205,Ann779,Ann591           NaN           NaN   \n",
      "\n",
      "      hard_label  \n",
      "0            NaN  \n",
      "1            NaN  \n",
      "2            NaN  \n",
      "3            NaN  \n",
      "4            NaN  \n",
      "...          ...  \n",
      "1099         NaN  \n",
      "1100         NaN  \n",
      "1101         NaN  \n",
      "1102         NaN  \n",
      "1103         NaN  \n",
      "\n",
      "[1104 rows x 6 columns]})\n"
     ]
    }
   ],
   "source": [
    "print(data.dataset_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params_lewidi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m def_params \u001b[39m=\u001b[39m params_lewidi()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'params_lewidi' is not defined"
     ]
    }
   ],
   "source": [
    "def_params = params_lewidi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "key = \"conv_train\"\n",
    "\n",
    "annotators = list(sorted(set(itertools.chain.from_iterable(data[key]['annotators'].str.findall(\"\\w+\")))))\n",
    "    \n",
    "model = ToxicityClassifier(data, annotators=annotators, params=def_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, results = model.CV()\n",
    "\n",
    "score[\"params\"] = \", \".join(key + \": \" + str(val) for key, val in def_params.__dict__.items())\n",
    "score[\"task\"] = model.params.task\n",
    "\n",
    "pacific = pytz.timezone('US/Pacific')\n",
    "sa_time = datetime.now(pacific)\n",
    "name_time = sa_time.strftime('%m%d%y-%H:%M')\n",
    "score[\"time\"] = name_time\n",
    "print(score)\n",
    "\n",
    "score_dir = os.path.join(def_params.source_dir, \"results\", \"GHC\", \"classification.csv\")\n",
    "result_dir = os.path.join(def_params.source_dir, \"results\", \"GHC\", name_time + \"_\" + def_params.task + \".csv\")\n",
    "if os.path.exists(score_dir):\n",
    "    pd.DataFrame.from_records([score]).to_csv(score_dir, header=False,  index=False, mode=\"a\")\n",
    "else:\n",
    "    pd.DataFrame.from_records([score]).to_csv(score_dir, index=False)\n",
    "\n",
    "    pd.DataFrame.from_dict(results).to_csv(result_dir, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('lewidi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ee0efadd74fe6f6eadb79affcde3681dbe393c6369e8c561aa7df3b7abce0814"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
